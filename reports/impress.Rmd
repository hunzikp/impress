---
title: 'impress: A geotagged dataset of scenic images'
author: "Philipp Hunziker"
date: "July 23, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**impress** is a dataset of 2611 geotagged scenic images collected from the [r/earthporn](http://www.reddit.com/r/earthporn) subreddit, a form where users submit original photographs of scenic landscapes. Each datum consists of a high-resolution image (typically > 1024x1024) together with submission-related data and an estimated geotag. 

You can find the metadata and some example images [here](https://github.com/hunzikp/impress/tree/master/data). (The image files are too large to upload to github in total.)

## Data aquisition

The submission data, including url-links to the submitted images, are collected using an [R-based command-line tool](https://raw.githubusercontent.com/hunzikp/impress/master/R/process_submissions.R) that uses the [Python Reddit API Wrapper](https://praw.readthedocs.io/en/latest/), accessed via [reticulate](https://github.com/rstudio/reticulate). The command-line tool listens to the Reddit API via a streaming iterator, and downloads submission information as soon as it is available on Reddit. The submission information (submission title, date, upvotes, etc) is then pushed into a [PostgreSQL database](https://www.postgresql.org/). The latter is to prevent loss-of-data in case of an error, and allows pulling data from Reddit with multiple machines in parallel. Given the submission data, we then download the submission image.

## Geparsing

As soon as a submission is streamed from the API, its title is geoparsed, i.e. we make a guess about the location mentioned in the title. This works because the r/earthporn subreddit mandates that submissions need to contain geographic information in the title.

We perform geoparsing using the [geonames](http://www.geonames.org/) location database, a data source containing the names and coordinates of over 9 million gegraphic features (e.g. places, parks, states, countries, etc.). Searching in this database naively (e.g. using grep) would be impractical and time-consuming. For this reason, we set up a local [elasticsearch](https://www.elastic.co/) engine, and use it to index the entire geonames database. We then geoparse titles by posting a [multi-match query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multi-match-query.html) to the search engine.  

## The data

The dataset currently encompases 2611 entries. Around 1000 of these entries consist of the top-rated submissions to r/earthporn, the rest are submissions collected by streaming the newest submissions since July 18th, 2018. (NOTE: We can't access earlier submissions easily due to the Reddit API's rate limits.)

Here's an extract of the metadata for illustration:

```{r load}
## Load the data
setwd("~/Projects/incubator/impress")
meta.df <- read.csv('data/meta.csv')
head(meta.df[,c("title", "created_date", "lat", "lon")])
```

And here's an example submission:

```{r im, echo = FALSE}
library(imager)

## Load an image
setwd("~/Projects/incubator/impress")
im <- load.image("data/3kne2j.jpg")
plot(im)
```












